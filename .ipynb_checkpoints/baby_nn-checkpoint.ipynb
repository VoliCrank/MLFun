{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32e65cff-b27b-4239-a513-4415ccad5a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cddd98ae-4992-419a-ae72-d5f5b1301c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9622e77e-e31b-4549-b49a-a8c97a448e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "optimizer = optim.SGD(params, lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3a88d5a-f9f7-40fc-89c3-51529130f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0eecddb2-a2ec-4c06-9946-0b9cad2cf71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data',train = True, download = True, transform = transforms.ToTensor())\n",
    "train,val = random_split(train_data, [55000,5000])\n",
    "train_loader = DataLoader(train,batch_size = 32)\n",
    "val_loader = DataLoader(val,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b12f65d9-683c-40b0-837e-f6f8ebe1f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,train loss:1.83,train accuracy:0.43\n",
      "Epoch 1,validation loss:0.74,validation accuracy: 0.80\n",
      "Epoch 2,train loss:0.50,train accuracy:0.85\n",
      "Epoch 2,validation loss:0.40,validation accuracy: 0.88\n",
      "Epoch 3,train loss:0.37,train accuracy:0.89\n",
      "Epoch 3,validation loss:0.33,validation accuracy: 0.91\n",
      "Epoch 4,train loss:0.31,train accuracy:0.91\n",
      "Epoch 4,validation loss:0.29,validation accuracy: 0.92\n",
      "Epoch 5,train loss:0.27,train accuracy:0.92\n",
      "Epoch 5,validation loss:0.26,validation accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    model.eval()\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        x,y, = batch\n",
    "        b = x.size(0)\n",
    "\n",
    "        #flatten image\n",
    "        x = x.view(b,-1)\n",
    "        \n",
    "        l = model(x)\n",
    "        J = loss(l,y)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        J.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(y.eq(l.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}', end = ',')\n",
    "    print(f'train loss:{torch.tensor(losses).mean():.2f}', end = ',')\n",
    "    print(f'train accuracy:{torch.tensor(accuracies).mean():.2f}')\n",
    "        \n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    for batch in val_loader:\n",
    "        \n",
    "        x,y, = batch\n",
    "        b = x.size(0)\n",
    "        #flatten image\n",
    "        x = x.view(b,-1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            l = model(x)\n",
    "        J = loss(l,y)\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(y.eq(l.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}',end= ',')\n",
    "    print(f'validation loss:{torch.tensor(losses).mean():.2f}',end = ',')\n",
    "    print(f'validation accuracy: {torch.tensor(accuracies).mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8f36ec8-c73a-4260-a2a2-5474798e36c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = datasets.MNIST('data',train = False, download = True, transform = transforms.ToTensor())\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bedee73d-761c-4f16-a1ad-ae3973b096de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = model(x)\n",
    "J = loss(l,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7af8d5-fa4e-4f94-b7d7-ad4e36cc6031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
